{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'invalid': 'ignore', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import os\n",
    "import itertools\n",
    "#import community\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "folder_directory =os.getcwd()\n",
    "os.chdir(folder_directory)\n",
    "execfile('python_libraries.py')\n",
    "execfile('parsing.py')  # Sam Way's Code\n",
    "execfile('mixing.py')   # Sam Way's Code\n",
    "execfile('create_adjacency_matrix.py')\n",
    "execfile('LINK.py')\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set-up LINK to compare -- is this just an easy prediction problem?\n",
    "edges = pd.read_csv('./by_month/all_months_years.csv',\n",
    "                   header = -1)\n",
    "edges.head()\n",
    "edges.drop(edges.columns[2], axis=1, inplace=True)\n",
    "#nx.from_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  2.0  3.0\n",
       "1  2.0  4.0\n",
       "2  2.0  5.0\n",
       "3  2.0  6.0\n",
       "4  2.0  7.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "#edges.head()\n",
    "df = pd.crosstab(edges[0], edges[1])\n",
    "idx = df.columns.union(df.index)\n",
    "df = df.reindex(index = idx, columns=idx, fill_value=0)\n",
    "#print np.sum(np.matrix(df),1)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.from_numpy_matrix(np.matrix(df))\n",
    "nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('./by_month/labels.csv')\n",
    "\n",
    "class_type = 'sloan' # mlgrad sloan\n",
    "\n",
    "if class_type =='sloan':\n",
    "    y['y']=((y.affil_clean=='sloan') | (y.affil_clean=='sloan_2'))+0\n",
    "if class_type == 'mlgrad':\n",
    "    y['y']=((y.affil_clean=='mlgrad') | (y.affil_clean=='1styeargrad') | (y.affil_clean=='grad '))+0\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = pd.DataFrame({'key':np.unique(np.concatenate((np.array(edges[0]),np.array(edges[1]))))})\n",
    "y_labels = y_labels.merge(y[['id','y']],\n",
    "              left_on = 'key',\n",
    "              right_on = 'id',\n",
    "              how = 'left')\n",
    "np.array(y_labels.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_initially_unlabelled = [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0.05]\n",
    "percent_initially_labelled = np.subtract(1, percent_initially_unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__\n",
    "\n",
    "from sklearn import cross_validation, datasets, linear_model\n",
    "n_iter = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "0.2\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "(mean_accuracy_LINK_RM, se_accuracy_LINK_RM, \n",
    " mean_micro_auc_LINK_RM,se_micro_auc_LINK_RM, mean_wt_LINK_RM,se_wt_LINK_RM)= LINK(percent_initially_unlabelled, ## note: mean_se_model assumes a vector of x% initially labeled\n",
    "                                                              np.array(y_labels.y), ## gender labels \n",
    "                                                              np.matrix(df), ## adjacency matrix\n",
    "                                                              clf = linear_model.LogisticRegression(penalty='l2',\n",
    "                                                                                                    solver='lbfgs',\n",
    "                                                                                                    C=10e20),\n",
    "                                                            num_iter=n_iter, \n",
    "                                                            cv_setup = 'stratified')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('./by_month/labels.csv')\n",
    "\n",
    "\n",
    "if class_type =='sloan':\n",
    "    y['y']=((y.affil_clean=='sloan') | (y.affil_clean=='sloan_2'))+0\n",
    "if class_type == 'mlgrad':\n",
    "    y['y']=((y.affil_clean=='mlgrad') | (y.affil_clean=='1styeargrad') | (y.affil_clean=='grad '))+0\n",
    "\n",
    "    \n",
    "x1= pd.read_csv('./by_month/refex-rolx-master-1/out_0.50_RealityMining_all_months_years.csv-featureValues.csv', header = -1)\n",
    "x2= pd.read_csv('./by_month/refex-rolx-master-2/out_0.50_RealityMining_all_months_years.csv-featureValues.csv', header = -1)\n",
    "x3= pd.read_csv('./by_month/refex-rolx-master-3/out_0.50_RealityMining_all_months_years.csv-featureValues.csv', header = -1)\n",
    "xall= pd.read_csv('./by_month/refex-rolx-master/out_0.50_RealityMining_all_months_years.csv-featureValues.csv', header = -1)\n",
    "\n",
    "#1x\n",
    "df1 = pd.DataFrame({'id':np.array(map(np.int,x1[0]))})\n",
    "\n",
    "y_label1 = df1.merge(y[['id','y']],\n",
    "            how = 'left',\n",
    "            on = 'id')\n",
    "x1= x1.loc[:,1::]\n",
    "scaler.fit(x1) #transform each feature on [0,1]-scale\n",
    "x1 = scaler.transform(x1)\n",
    "\n",
    "\n",
    "#2x\n",
    "df2 = pd.DataFrame({'id':np.array(map(np.int,x2[0]))})\n",
    "\n",
    "y_label2 = df2.merge(y[['id','y']],\n",
    "            how = 'left',\n",
    "            on = 'id')\n",
    "x2= x2.loc[:,1::]\n",
    "scaler.fit(x2) #transform each feature on [0,1]-scale\n",
    "x2 = scaler.transform(x2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#3x\n",
    "df3 = pd.DataFrame({'id':np.array(map(np.int,x3[0]))})\n",
    "\n",
    "y_label3 = df3.merge(y[['id','y']],\n",
    "            how = 'left',\n",
    "            on = 'id')\n",
    "x3= x3.loc[:,1::]\n",
    "scaler.fit(x3) #transform each feature on [0,1]-scale\n",
    "x3 = scaler.transform(x3)\n",
    "\n",
    "\n",
    "\n",
    "#all\n",
    "dfall = pd.DataFrame({'id':np.array(map(np.int,xall[0]))})\n",
    "\n",
    "y_labelall = dfall.merge(y[['id','y']],\n",
    "            how = 'left',\n",
    "            on = 'id')\n",
    "xall= xall.loc[:,1::]\n",
    "scaler.fit(xall) #transform each feature on [0,1]-scale\n",
    "xall = scaler.transform(xall)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = True # else continues using LogForest models from earlier\n",
    "undersampling = False\n",
    "n_iter_num = 25\n",
    "if RF:\n",
    "    if undersampling:\n",
    "        ## add in -- undersampling possibly\n",
    "        max_depth = [3, 5, 10]\n",
    "        max_depth.append(None)\n",
    "        min_samples_leaf = [0.05, 0.1, 0.2]\n",
    "        min_samples_split = [2, 3, 4, 5, 10]\n",
    "        n_estimators = [ 100, 150] #[10, 50, 100, 150, 200]\n",
    "        max_features = ['auto', 0.25, 0.5, 0.75]\n",
    "        random_grid = {'clf__max_depth': max_depth,\n",
    "                     'clf__min_samples_leaf': min_samples_leaf,\n",
    "                     'clf__max_features': max_features,\n",
    "                      'clf__n_estimators': n_estimators,\n",
    "                      'clf__min_samples_split': min_samples_split\n",
    "        }\n",
    "\n",
    "        clf = sklearn.ensemble.RandomForestClassifier()\n",
    "        pipeline = imbPipeline([('undersample', imblearn.under_sampling.RandomUnderSampler(random_state=567)),\n",
    "                                    #('oversample',imblearn.over_sampling.SMOTE()), \n",
    "                            ('clf',clf)])\n",
    "        model1 = RandomizedSearchCV(estimator = pipeline,\n",
    "                param_distributions = random_grid,\n",
    "                cv = 3, verbose=0,\n",
    "                n_jobs = 2)\n",
    "\n",
    "        model2 = RandomizedSearchCV(estimator = pipeline,\n",
    "                param_distributions = random_grid,\n",
    "                cv = 3, verbose=0,\n",
    "                n_jobs = 2)\n",
    "\n",
    "        model3 = RandomizedSearchCV(estimator = pipeline,\n",
    "                param_distributions = random_grid,\n",
    "                cv = 3, verbose=0,\n",
    "                n_jobs = 2)\n",
    "\n",
    "        modelall = RandomizedSearchCV(estimator = pipeline,\n",
    "                param_distributions = random_grid,\n",
    "                cv = 3, verbose=0,\n",
    "                n_jobs = 2)\n",
    "    else:\n",
    "        max_depth = [3, 5, 10]\n",
    "        max_depth.append(None)\n",
    "        min_samples_leaf = [1]\n",
    "        min_samples_split = [2] #[2, 3, 4, 5, 10]\n",
    "        n_estimators = [100, 1000]#150]\n",
    "        max_features = ['auto', 0.25, 0.5, 0.75]\n",
    "        random_grid = {'max_depth': max_depth,\n",
    "                        'min_samples_leaf': min_samples_leaf,\n",
    "                        'max_features': max_features,\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'min_samples_split': min_samples_split,\n",
    "                       'class_weight': [{1:0.505, 1:50.5},{1:0.51, 1:25.5},{1:0.525, 1:10.5},{1:0.55, 1:5.5}]\n",
    "                        }\n",
    "\n",
    "        clf = sklearn.ensemble.RandomForestClassifier()\n",
    "        model1 = RandomizedSearchCV(estimator = clf, n_iter = n_iter_num,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   cv = 3, verbose=0,\n",
    "                                   n_jobs = 9)\n",
    "\n",
    "        model2 = RandomizedSearchCV(estimator = clf,\n",
    "                                    param_distributions = random_grid,\n",
    "                                    cv = 3, verbose=0,n_iter = n_iter_num,\n",
    "                                    n_jobs = 9)\n",
    "        model3 = RandomizedSearchCV(estimator = clf,\n",
    "                                    param_distributions = random_grid,\n",
    "                                    cv = 3, verbose=0,n_iter = n_iter_num,\n",
    "                                    n_jobs = 9)\n",
    "        modelall = RandomizedSearchCV(estimator = clf,\n",
    "                                    param_distributions = random_grid,\n",
    "                                    cv = 3, verbose=0,n_iter = n_iter_num,\n",
    "                                    n_jobs =9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.136207</td>\n",
       "      <td>-0.085100</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>-0.058467</td>\n",
       "      <td>-0.018517</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>0.046466</td>\n",
       "      <td>0.026082</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107775</td>\n",
       "      <td>-0.035662</td>\n",
       "      <td>-0.087083</td>\n",
       "      <td>-0.029418</td>\n",
       "      <td>-0.118273</td>\n",
       "      <td>-0.067824</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.095207</td>\n",
       "      <td>-0.163948</td>\n",
       "      <td>-0.223055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.132249</td>\n",
       "      <td>-0.078536</td>\n",
       "      <td>0.022701</td>\n",
       "      <td>-0.050319</td>\n",
       "      <td>-0.018928</td>\n",
       "      <td>0.083171</td>\n",
       "      <td>0.043562</td>\n",
       "      <td>0.022488</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098503</td>\n",
       "      <td>-0.033239</td>\n",
       "      <td>-0.081079</td>\n",
       "      <td>-0.026492</td>\n",
       "      <td>-0.112709</td>\n",
       "      <td>-0.067217</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.094674</td>\n",
       "      <td>-0.163911</td>\n",
       "      <td>-0.211333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.136785</td>\n",
       "      <td>-0.080742</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>-0.052969</td>\n",
       "      <td>-0.012840</td>\n",
       "      <td>0.089094</td>\n",
       "      <td>0.044227</td>\n",
       "      <td>0.027157</td>\n",
       "      <td>0.043876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101755</td>\n",
       "      <td>-0.037051</td>\n",
       "      <td>-0.082570</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>-0.108793</td>\n",
       "      <td>-0.065152</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.093828</td>\n",
       "      <td>-0.157694</td>\n",
       "      <td>-0.212824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.081681</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.054405</td>\n",
       "      <td>-0.013386</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>0.023713</td>\n",
       "      <td>0.041753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097982</td>\n",
       "      <td>-0.040126</td>\n",
       "      <td>-0.078636</td>\n",
       "      <td>-0.030004</td>\n",
       "      <td>-0.107275</td>\n",
       "      <td>-0.066228</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>0.096266</td>\n",
       "      <td>-0.155454</td>\n",
       "      <td>-0.212905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.134223</td>\n",
       "      <td>-0.079952</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>-0.048476</td>\n",
       "      <td>-0.012420</td>\n",
       "      <td>0.086209</td>\n",
       "      <td>0.038777</td>\n",
       "      <td>0.025724</td>\n",
       "      <td>0.039649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095069</td>\n",
       "      <td>-0.035510</td>\n",
       "      <td>-0.081300</td>\n",
       "      <td>-0.025945</td>\n",
       "      <td>-0.112942</td>\n",
       "      <td>-0.062278</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.088536</td>\n",
       "      <td>-0.157139</td>\n",
       "      <td>-0.205110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0  100  0.136207 -0.085100  0.027711 -0.058467 -0.018517  0.090901  0.046466   \n",
       "1    3  0.132249 -0.078536  0.022701 -0.050319 -0.018928  0.083171  0.043562   \n",
       "2    7  0.136785 -0.080742  0.017946 -0.052969 -0.012840  0.089094  0.044227   \n",
       "3   22  0.133923 -0.081681  0.022322 -0.054405 -0.013386  0.087281  0.040759   \n",
       "4   24  0.134223 -0.079952  0.019743 -0.048476 -0.012420  0.086209  0.038777   \n",
       "\n",
       "        8         9      ...          119       120       121       122  \\\n",
       "0  0.026082  0.041344    ...     0.107775 -0.035662 -0.087083 -0.029418   \n",
       "1  0.022488  0.036000    ...     0.098503 -0.033239 -0.081079 -0.026492   \n",
       "2  0.027157  0.043876    ...     0.101755 -0.037051 -0.082570 -0.028697   \n",
       "3  0.023713  0.041753    ...     0.097982 -0.040126 -0.078636 -0.030004   \n",
       "4  0.025724  0.039649    ...     0.095069 -0.035510 -0.081300 -0.025945   \n",
       "\n",
       "        123       124       125       126       127       128  \n",
       "0 -0.118273 -0.067824  0.001471  0.095207 -0.163948 -0.223055  \n",
       "1 -0.112709 -0.067217  0.006711  0.094674 -0.163911 -0.211333  \n",
       "2 -0.108793 -0.065152  0.003769  0.093828 -0.157694 -0.212824  \n",
       "3 -0.107275 -0.066228 -0.001584  0.096266 -0.155454 -0.212905  \n",
       "4 -0.112942 -0.062278  0.005179  0.088536 -0.157139 -0.205110  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## node2vec\n",
    "n2v_RM = pd.read_csv('./RM.emb',\n",
    "                      skiprows=1,\n",
    "                    header = None,\n",
    "                      sep=' ')\n",
    "n2v_RM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.DataFrame(n2v_RM[0])\n",
    "tmp.columns = ['keys']\n",
    "\n",
    "y_labels = tmp.merge(y[['id','y']],\n",
    "              left_on = 'keys',\n",
    "              right_on = 'id',\n",
    "              how = 'left')\n",
    "np.sum(y_labels['keys']!=n2v_RM[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_RM.drop(0, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_RM =n2v_RM[~np.isnan(y_labels.y)]\n",
    "y_labels =y_labels[~np.isnan(y_labels.y)]\n",
    "n_iter = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05*np.sum(y_labels.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Model\n",
    "(mean_accuracy_node2vec, se_accuracy_node2vec, \n",
    " mean_micro_auc_node2vec,se_micro_auc_node2vec, mean_wt_node2vec_C,se_wt_node2vec)= LINK(percent_initially_unlabelled, ## note: mean_se_model assumes a vector of x% initially labeled\n",
    "                                                              np.array(y_labels.y).astype(np.int), ## gender labels \n",
    "                                                              np.matrix(n2v_RM), ## adjacency matrix\n",
    "                                                       clf = modelall,\n",
    "                                                                                   num_iter=n_iter, \n",
    "                                                                     cv_setup = 'stratified')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "0.2\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "(mean_accuracy_x1, se_accuracy_x1, \n",
    " mean_micro_auc_x1,se_micro_auc_x1, mean_wt_auc_x1_lbfgs,se_wt_auc_x1)= LINK(percent_initially_unlabelled, ## note: mean_se_model assumes a vector of x% initially labeled\n",
    "                                                              np.array(y_label1.y), ## gender labels \n",
    "                                                              np.matrix(x1), ## adjacency matrix\n",
    "                                                              clf = model1,num_iter=n_iter, cv_setup = 'stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "0.2\n",
      "0.1\n",
      "0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaltenb/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "(mean_accuracy_x2, se_accuracy_x2, \n",
    " mean_micro_auc_x2,se_micro_auc_x2, mean_wt_auc_x2_lbfgs,se_wt_auc_x2)= LINK(percent_initially_unlabelled, ## note: mean_se_model assumes a vector of x% initially labeled\n",
    "                                                              np.array(y_label2.y), ## gender labels \n",
    "                                                              np.matrix(x2), ## adjacency matrix\n",
    "                                                              clf = model2,num_iter=n_iter, cv_setup = 'stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "0.2\n",
      "0.1\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "(mean_accuracy_x3, se_accuracy_x3, \n",
    " mean_micro_auc_x3,se_micro_auc_x3, mean_wt_auc_x3_lbfgs,se_wt_auc_x3)= LINK(percent_initially_unlabelled, ## note: mean_se_model assumes a vector of x% initially labeled\n",
    "                                                              np.array(y_label3.y), ## gender labels \n",
    "                                                              np.matrix(x3), ## adjacency matrix\n",
    "                                                              clf = model3,num_iter=n_iter, cv_setup = 'stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "0.2\n",
      "0.1\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "(mean_accuracy_xall, se_accuracy_xall, \n",
    " mean_micro_auc_xall,se_micro_auc_xall, mean_wt_auc_xall_lbfgs,se_wt_auc_xall)= LINK(percent_initially_unlabelled, ## note: mean_se_model assumes a vector of x% initially labeled\n",
    "                                                              np.array(y_labelall.y), ## gender labels \n",
    "                                                              np.matrix(xall), ## adjacency matrix\n",
    "                                                              clf = modelall,num_iter=n_iter, cv_setup = 'stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({'mean_wt_auc_x1_lbfgs': mean_wt_auc_x1_lbfgs,\n",
    "                            'se_wt_auc_x1': se_wt_auc_x1,\n",
    "                            'mean_wt_auc_x2_lbfgs': mean_wt_auc_x2_lbfgs,\n",
    "                            'se_wt_auc_x2': se_wt_auc_x2,\n",
    "                            'mean_wt_auc_x3_lbfgs': mean_wt_auc_x3_lbfgs,\n",
    "                            'se_wt_auc_x3': se_wt_auc_x3,\n",
    "                            'mean_wt_auc_xall_lbfgs': mean_wt_auc_xall_lbfgs,\n",
    "                            'se_wt_auc_xall': se_wt_auc_xall,\n",
    "                           'mean_wt_LINK_RM':mean_wt_LINK_RM,\n",
    "                           'se_wt_LINK_RM': se_wt_LINK_RM,\n",
    "                           'mean_wt_node2vec':mean_wt_node2vec,\n",
    "                           'se_wt_node2vec':se_wt_node2vec,\n",
    "                            })\n",
    "df_results.to_csv('NEWRMesults.csv',sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
